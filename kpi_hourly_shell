#!/usr/bin/bash
################################################################################
################################################################################
##### Author: Sarvani A
#####    This script is using to load RTT KPI hourly aggregated data to hive
################################################################################
################################################################################
if [[ -z $STPBASE ]]
then
  echo "STPBASE not set, cannot proceed further."
  exit 1
fi

. $STPBASE/config/load_stp_config.cfg

### Global Variables for this script
PROCESS=$(basename ${0%.*})
PERMITDIR=$STP_RTT_KPI_SUMMARY_HOURLY_PERMIT_DIR
LOGDIR=$STP_RTT_KPI_SUMMARY_HOURLY_LOG_DIR
LOGPREFIX=$STP_RTT_KPI_SUMMARY_HOURLY_LOG_FILE_PREFIX
PIGSCRIPT=$STP_RTT_KPI_SUMMARY_HOURLY_SHELL_PIG_SCRIPT
PIGMODE=$STP_RTT_KPI_SUMMARY_HOURLY_PIG_MODE
SOURCE_SCHEMA=$STP_RTT_KPI_SUMMARY_HOURLY_INPUT_HIVE_SCHEMA
P_TABLE=$STP_RTT_KPI_SUMMARY_HOURLY_INPUT_HIVE_TABLE
P_TABLE_HDFS_PATH=$STP_RTT_KPI_SUMMARY_HOURLY_HDFS_INPATH
SUBSCRIBER_SCHEMA=$STP_RTT_KPI_SUMMARY_SUBSCRIBER_SCHEMA
SUBSCRIBER_TBL=$STP_RTT_KPI_SUMMARY_SUBSCRIBER_PROFILE_TABLE
HDFS_OUTPATH=$STP_RTT_KPI_SUMMARY_HOURLY_HDFS_OUTPATH
HDFS_INPATH=$STP_RTT_KPI_SUMMARY_HOURLY_HDFS_INPATH
DELIM=$STP_RTT_KPI_SUMMARY_HOURLY_DELIM
OUT_TBL=$STP_RTT_KPI_SUMMARY_HOURLY_HIVE_OUT_EXT_TABL
INTEGRATE_KPI_SUMMARY_DAILY=$STP_RTT_KPI_SUMMARY_HOURLY_INTEGRATE_DAILY_SCRIPT_FLAG
DAILY_SCRIPT=$STP_RTT_KPI_SUMMARY_DAILY_SHELL_SCRIPT
LATENCYMINS=$STP_RTT_KPI_SUMMARY_HOURLY_LATENCY_MINS
KPI_CTL_FILE=$STP_RTT_KPI_SUMMARY_HOURLY_CTL_FILE
PARTITION_THRESHOLD_TOTAL=$STP_RTT_KPI_SUMMARY_HOURLY_P_TABLE_PARTITION_COUNT
PARTITION_THRESHOLD_PERCENTAGE=$STP_RTT_KPI_SUMMARY_HOURLY_P_TABLE_PARTITION_THRESHOLD_PERCENTAGE
PARTIAL_PARTITION_PROCESSING=$STP_RTT_KPI_SUMMARY_HOURLY_P_TABLE_PARTITION_PARTIAL_PROCESSING
PARTIAL_PARTITION_SEND_MAIL=$STP_RTT_KPI_SUMMARY_HOURLY_P_TABLE_PARTITION_PARTIAL_SEND_MAIL
PARTIAL_PARTITION_MAIL_SUBJECT=$STP_RTT_KPI_SUMMARY_HOURLY_P_TABLE_PARTITION_PARTIAL_MAIL_SUBJECT
MAIL_RECEPIENTS=$STP_RTT_KPI_SUMMARY_HOURLY_MAIL_RECEPIENTS
MISSING_PARTITION_PROCESSING=$STP_RTT_KPI_SUMMARY_HOURLY_P_TABLE_PARTITION_MISSING_PROCESSING
MISSING_PARTITION_SEND_MAIL=$STP_RTT_KPI_SUMMARY_HOURLY_P_TABLE_PARTITION_MISSING_SEND_MAIL
MISSING_PARTITION_MAIL_SUBJECT=$STP_RTT_KPI_SUMMARY_HOURLY_P_TABLE_PARTITION_MISSING_MAIL_SUBJECT
MAX_INST_IN_PARELLEL=$STP_RTT_KPI_SUMMARY_HOURLY_NUM_INSTANCES_IN_PARELLEL
LOAD_STATUS_TBL_SCRIPT=$STP_RTT_KPI_SUMMARY_HOURLY_LOAD_STATUS_TBL_SCRIPT
MAX_WAIT_SECS=$STP_RTT_KPI_SUMMARY_HOURLY_LOAD_STATUS_TBL_SCRIPT_WAIT_SECS
MAX_ITERATIONS=$STP_RTT_KPI_SUMMARY_HOURLY_LOAD_STATUS_TBL_SCRIPT_WAIT_ITERATIONS
STATUS_DIR=$STP_RTT_KPI_SUMMARY_HOURLY_STATUS_OUT_DIR

HDFS_VOICE_INVALID_IMSI_OUTPATH=$STP_RTT_KPI_SUMMARY_HOURLY_VOICE_INVALID_IMSI_HDFS_OUTPATH
P_SIP_TABLE=$STP_RTT_KPI_SUMMARY_HOURLY_VOICE_SIP_INPUT_TABLE
P_RTP_TABLE=$STP_RTT_KPI_SUMMARY_HOURLY_VOICE_RTP_INPUT_TABLE
P_SIP_SCHEMA=$STP_RTT_KPI_SUMMARY_HOURLY_VOICE_SIP_INPUT_SCHEMA
P_RTP_SCHEMA=$STP_RTT_KPI_SUMMARY_HOURLY_VOICE_RTP_INPUT_SCHEMA
VOICE_IMSI_LIST_OUT_TBL=$STP_RTT_KPI_SUMMARY_HOURLY_VOICE_KPI_NO_MATCH_IMSI_LIST_OUT_TABLE

#export HADOOP_HEAPSIZE=1500
#export PIG_HEAPSIZE=1500
################################################################################
################################################################################
##### Function: Usage
Usage()
{
    echo "Unknown arguments $@ passed to the script."
    echo "Usage: stp_rtt_load_kpi_summary_hourly.sh                                                                                          "
    echo "                           OR                                                                                                      "
    echo "Usage: stp_rtt_load_kpi_summary_hourly.sh [trans_dt in yyyy-MM-dd] [trans_hr in HH (00-23)]                                        "
    exit 1
}

################################################################################
################################################################################
##### Function: InstanceCheck
InstanceCheck()
{

    if [[ -f "$3" ]];
    then
      scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" "[InstanceCheck] Instance for $1 $2 is already running. Exiting."
      #Dont remove PIDFILE, just exit the script.
      exit 1
    fi

    ## See if the PID file exists and if it doesn't, we're good.
    cnt=0
    pids=`cat $PERMITDIR/*.pid`
    scriptLogger $LOGFILE $PROCESS $$ "[INFO]" "[InstanceCheck] pids = $pids"
    for pid in $pids
    do
      scriptLogger $LOGFILE $PROCESS $$ "[INFO]" "[InstanceCheck] for loop for -  $pid"
      ps -fp $pid | grep $PROCESS > /dev/null 2>&1
      if [[ $? == 0 ]]
      then
        cnt=$cnt+1
      fi
    done
    scriptLogger $LOGFILE $PROCESS $$ "[INFO]" "[InstanceCheck] No.of Running instances - $cnt"
    if [[ $cnt -ge $MAX_INST_IN_PARELLEL ]]
    then
      scriptLogger $LOGFILE $PROCESS $$ "[INFO]" "[InstanceCheck] No more instances can be run in parallel. Exiting "
      exit 1
    else
      scriptLogger $LOGFILE $PROCESS $$ "[INFO]" "[InstanceCheck] Scope for another instance run. Good to go"
      return 0
    fi
}

################################################################################
################################################################################
##### Function: PrepareEnv
PrepareEnv()
{
  ## Make the necessary directories.
  mkdir -p $LOGDIR
  mkdir -p $PERMITDIR
}

################################################################################
################################################################################
##### Function: WritePIDFile
WritePIDFile()
{
  ## Write the PID to PID file.
  echo $$ > $1
}
################################################################################
################################################################################
##### Function: checkHr
checkHr()
{
  if [[ $(date "+%Y-%m-%d %H" -d "$1 $2") == "$1 $2" ]]
  then
    scriptLogger $LOGFILE $PROCESS $$  "[INFO]" " Valid argument. Proceeding to Process."
  else
    Usage
  fi
}

################################################################################
################################################################################
##### Function: checkIfInvalidTime
checkIfInvalidTime()
{
  latency=$LATENCYMINS
  curdate=`date -d "-$latency minutes" "+%s"`
  prevDate=`cat $KPI_CTL_FILE`":00"
  prevtimestamp="$(date -d "$prevDate" '+%s')"
  if [[ $prevtimestamp -ge $curdate ]]
  then
    scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" " Process runtime ($prevtimestamp) is >= process last run time ($curdate). Exiting..."
    ProcessEnd
  else
    return 0
  fi
}
################################################################################
################################################################################
##### Function: ValidateArgs
ValidateArgs()
{
  if [[ $# -eq 0 ]]
  then
    #Check for last run dt/hr and consider load_date_hr as last run dt/hr + 1
    if [[ -s $KPI_CTL_FILE ]]
    then
      to_run_time=`cat $KPI_CTL_FILE`
      toruntimestamp="$(date -d "$to_run_time" '+%s')"
      currentLoadInterval=$(($toruntimestamp))
      trans_dt=`date -d"@$currentLoadInterval" '+%Y-%m-%d'`
      trans_hr=`date -d"@$currentLoadInterval" '+%H'`	  
      LOGFILE=$LOGPREFIX'.'$trans_dt'_'$trans_hr'.log'
      checkIfInvalidTime
    else
      #Take latency hours config and calculate day, hr 
      latency=$LATENCYMINS
      curtimestamp=`date -d "-$latency minutes" "+%s"`
      trans_dt=`date -d"@$curtimestamp" '+%Y-%m-%d'`
      trans_hr=`date -d"@$curtimestamp" '+%H'`
      LOGFILE=$LOGPREFIX'.'$trans_dt'_'$trans_hr'.log'
    fi

    flagWriteToctl=1
	
  elif [[ $# -eq 2 ]]
  then
    flagWriteToctl=0
    #date and hour are given
    trans_dt=$1
    trans_hr=$2
    LOGFILE=$LOGPREFIX'.'$trans_dt'_'$trans_hr'.log'
    checkHr $trans_dt $trans_hr

    flagWriteToctl=0

  else
    Usage
  fi
}
################################################################################
################################################################################
##### Function: DropIfExistsHDFSPartition
DropIfExistsHDFSPartition()
{
  hadoop fs -test -d "$1" >> $LOGFILE 2>&1
  
  if [[ $? -ne 0 ]]
  then
    scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " NO prior partition found $1. Good to go."
    return 0
  else
    hadoop fs -rm -r -skipTrash "$1" >> $LOGFILE 2>&1
    if [[  $? -ne 0  ]]
    then
      scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" " Failed to remove HDFS folder $1"
      ProcessEnd
    else
      scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Successfully removed HDFS partition $1. Good to go."
    fi
  fi
}
################################################################################
################################################################################
##### Function: WriteToCtlFile
WriteToCtlFile()
{
  cur_dt_hr="$1 $2:00"
  cur_ts="$(date -d "$cur_dt_hr" '+%s')"
  write_timestamp=$(($cur_ts+60 * 60))
  write_dt=`date -d"@$write_timestamp" '+%Y-%m-%d'`
  write_hr=`date -d"@$write_timestamp" '+%H'`
  echo $write_dt $write_hr:00 > $KPI_CTL_FILE
  scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Successfully written timestamp to $write_dt $write_hr:00 to $KPI_CTL_FILE"
  
  return 0
}
################################################################################
################################################################################
##### Function: CallDailyScript
CallDailyScript()
{
  if [[ $INTEGRATE_KPI_SUMMARY_DAILY -eq 1 ]]
  then
    scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Calling $DAILY_SCRIPT to aggregate kpi-summary at daily level"
    $DAILY_SCRIPT $1
    scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Check logs at $STP_LOAD_RTT_KPI_SUMMARY_DAILY_LOG_FILE"
  fi  
}

################################################################################
################################################################################
##### Function: CallEventQciPigScript
CallPigScript()
{
  input_date=$1
  tHr=$2
 
  DropIfExistsHDFSPartition $STP_RTT_KPI_SUMMARY_HOURLY_HDFS_OUTPATH/trans_dt=$input_date/trans_hr=$tHr
  DropIfExistsHDFSPartition $HDFS_VOICE_INVALID_IMSI_OUTPATH/trans_dt=$input_date/trans_hr=$tHr
  DropIfExistsHDFSPartition $STATUS_DIR/trans_dt=$input_date/trans_hr=$tHr
  
  scriptLogger $LOGFILE $PROCESS $$ "[INFO]" "/usr/bin/pig -Dpig.additional.jars=$PIGGYBANK_JAR -Dexectype=$PIGMODE \
               -useHCatalog -t ColumnMapKeyPrune -f $PIGSCRIPT -l $LOGFILE \
               -param source_schema=$SOURCE_SCHEMA \
               -param source_table=$P_TABLE \
               -param source_sip_schema=$P_SIP_SCHEMA \
               -param source_sip_table=$P_SIP_TABLE \
               -param source_rtp_schema=$P_RTP_SCHEMA \
               -param source_rtp_table=$P_RTP_TABLE \
               -param subscriber_schema=$SUBSCRIBER_SCHEMA \
               -param subscriber_table=$SUBSCRIBER_TBL \
               -param trans_dt=$input_date \ 
               -param trans_hr=$tHr \ 
               -param hdfs_out_path=$HDFS_OUTPATH \
               -param hdfs_voice_invalid_imsis_out_path=$HDFS_VOICE_INVALID_IMSI_OUTPATH \
               -param status_dir=$STATUS_DIR \
               -param out_delim=$DELIM >>$LOGFILE 2>&1"
  
  /usr/bin/pig -Dpig.additional.jars=$PIGGYBANK_JAR -Dexectype=$PIGMODE \
               -useHCatalog -t ColumnMapKeyPrune -f $PIGSCRIPT -l $LOGFILE \
               -param source_schema=$SOURCE_SCHEMA \
               -param source_table=$P_TABLE \
               -param source_sip_schema=$P_SIP_SCHEMA \
               -param source_sip_table=$P_SIP_TABLE \
               -param source_rtp_schema=$P_RTP_SCHEMA \
               -param source_rtp_table=$P_RTP_TABLE \
               -param subscriber_schema=$SUBSCRIBER_SCHEMA \
               -param subscriber_table=$SUBSCRIBER_TBL \
               -param trans_dt=$input_date \
               -param trans_hr=$tHr \
               -param hdfs_out_path=$HDFS_OUTPATH \
               -param hdfs_voice_invalid_imsis_out_path=$HDFS_VOICE_INVALID_IMSI_OUTPATH \
               -param status_dir=$STATUS_DIR \
               -param out_delim=$DELIM >>$LOGFILE 2>&1
 
  if [[ $? -ne 0 ]]
  then
    scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" " Failed to aggregate hourly KPI summary at $HDFS_OUTPATH/trans_date=$input_date/trans_hr=$tHr. See log for more details."
    ProcessEnd
  else
    scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Successfully aggregated hourly KPI summary at $HDFS_OUTPATH/trans_date=$input_date/trans_hr=$tHr."

    scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Calling Load Status table script..."
    no_of_iterations=0
    #Call load status tbl script in a loop, wait if it is already running
    while [[ 1 ]]
    do
      if [[ $no_of_iterations -ge $MAX_ITERATIONS ]]
      then
        scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" "$LOAD_STATUS_TBL_SCRIPT is busy. Tried Max iterations ($MAX_ITERATIONS). Exiting."
        ProcessEnd
      fi

      sh $LOAD_STATUS_TBL_SCRIPT $input_date $tHr >> $LOGFILE 2>&1
      rc=$?
      if [[ $rc -eq 2 ]]
      then
        scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " $LOAD_STATUS_TBL_SCRIPT is busy. Waiting...." 
        sleep $MAX_WAIT_SECS
        no_of_iterations=$no_of_iterations+1
      elif [[ $rc -eq 1 ]]
      then
        scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" " Error while loading data to status table $LOAD_STATUS_TBL_SCRIPT. Check detailed logs at $LOAD_STATUS_TBL_SCRIPT. Exiting..."
        ProcessEnd
      else
        scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Successfully updated status table $STATUS_SCRIPT for trans_dt=$trans_dt trans_hr=$trans_hr."
        if [[ $trans_hr -eq 23 ]]
        then
          CallDailyScript $trans_dt
        fi 
        return 0
      fi
    done
  fi
}

################################################################################
################################################################################
##### Function: CheckIfExistsHDFSPath
CheckIfExistsHDFSPath()
{ 
  scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " hadoop fs -test -d $1"
  
  hadoop fs -test -d "$1"
  
  if [[ $? -ne 0 ]]
  then
	if [[ $MISSING_PARTITION_PROCESSING == 'Y' ]]
	then
	  scriptLogger $LOGFILE $PROCESS $$ "[WARN]" " Current partition $1 is missing. Updating control file to next hour"
	  CheckIfNoPartitionData $1
	else
	  scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" " Input path not found at $1. Exiting." 
          ProcessEnd
	fi
  else
    return 0
  fi
}

################################################################################
################################################################################
##### Function: CheckIfNoPartitionData
CheckIfNoPartitionData()
{
  partition=$1
  prev_run_time=`cat $KPI_CTL_FILE`
  prevtimestamp="$(date -d "$prev_run_time" '+%s')"
  currentLoadInterval=$(($prevtimestamp))
  trans_dt=`date -d"@$currentLoadInterval" '+%Y-%m-%d'`
  trans_hr=`date -d"@$currentLoadInterval" '+%H'`
  WriteToCtlFile $trans_dt $trans_hr
  
  if [[ $MISSING_PARTITION_SEND_MAIL == 'Y' ]]
  then
     scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Sending mail alert with subject:$MISSING_PARTITION_MAIL_SUBJECT to team $MAIL_RECEPIENTS as : P_TABLE PARTITION: $partition is missing in current table. Please re-run it manually"
     
     echo -e P_TABLE PARTITION: $partition is missing in current table.\\nPlease re-run it manually.\\n\\n\\nTHIS IS AN AUTOMATED MESSAGE - PLEASE DO NOT REPLY TO THIS EMAIL |  mailx -s "$MISSING_PARTITION_MAIL_SUBJECT" $MAIL_RECEPIENTS
	 
     if [[  $? -ne 0  ]]
     then
       scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" " Failure in sending mail to team regarding P_Table Partition Missing"
       ProcessEnd
     else
       scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Successfully mail sent to team regarding P_Table Partition Missing"
     fi
	 
  fi
  
  ProcessEnd 
}

################################################################################
################################################################################
##### Function: CheckIfPartialData
CheckIfPartialData()
{   
  partition=$1

  scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " P_TABLE p_date_key Partition values : $partition"
 
  scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Executing query : select count(*) from $SOURCE_SCHEMA.$P_TABLE where  p_date_key like '%$partition%'"
 
  count=$(/usr/bin/hive -e "select count(*) from $SOURCE_SCHEMA.$P_TABLE where p_date_key like '%$partition%'")>>$LOGFILE 2>&1
  
  if [[ $? -ne 0 ]]
  then
    scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" " Partition counts query failed. Exiting." 
    ProcessEnd
  fi
  
  partition_percent=$(awk "BEGIN { pc=100*${count}/${PARTITION_THRESHOLD_TOTAL}; i=int(pc); print (pc-i<0.5)?i:i+1 }")
  
  if [[ $partition_percent -ge $PARTITION_THRESHOLD_PERCENTAGE ]]
  then
     scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " P_TABLE $1 partition has sufficient data for execution Counts:$count, Percentage:$partition_percent"
     return 0
  else
     scriptLogger $LOGFILE $PROCESS $$ "[WARN]" " P_TABLE $1 partition has partial data for execution Counts:$count, Percentage:$partition_percent"
	 
     if [[ $PARTIAL_PARTITION_SEND_MAIL == 'Y' ]]
     then
       scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Sending mail alert with subject:$PARTIAL_PARTITION_MAIL_SUBJECT to team $MAIL_RECEPIENTS as : P_TABLE PARTITION: $1 has below counts and percentage of records. Counts:$count Percentage:$partition_percent"
	   
       echo -e P_TABLE PARTITION: $1 has below counts and percentage of records. \\nCounts:$count \\nPercentage:$partition_percent\\n\\n\\nTHIS IS AN AUTOMATED MESSAGE - PLEASE DO NOT REPLY TO THIS EMAIL  | mailx -s "$PARTIAL_PARTITION_MAIL_SUBJECT" $MAIL_RECEPIENTS
	   
       if [[  $? -ne 0  ]]
       then
         scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" " Failure in sending mail to team regarding P_Table Partial Partition"
         ProcessEnd
       else
         scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Successfully mail sent to team regarding P_Table Partial Partition"
       fi
	   
     fi
	 
     if [[ $count -ne 0 ]]
     then
         return 0
     else
         scriptLogger $LOGFILE $PROCESS $$ "[ERROR]" " P_TABLE p_date_key partition: $partition has zero records. So exiting the process"
         ProcessEnd
     fi
  fi  
}

################################################################################
################################################################################
##### Function: ProcessEnd
ProcessEnd()
{
 rm -f $PIDFILE >>$LOGFILE 2>&1
 scriptLogger $LOGFILE $PROCESS $$ "[INFO]" "----- Process END -----"
 exit 1
}

################################################################################
################################################################################
##### Function: CoreLogic
CoreLogic()
{
  trans_dt=$1
  trans_hr=$2
  idate=${trans_dt//-}
  scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Beginning the processing for KPI Aggrgator summary for $trans_dt $trans_hr:00"
  scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Checking P_table partition in HDFS"

  CheckIfExistsHDFSPath $P_TABLE_HDFS_PATH/p_date_key=$idate$trans_hr*
  scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Checking  in HDFS"
  
  if [[ $PARTIAL_PARTITION_PROCESSING == 'Y' ]]
  then
    scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Checking P_table partition partial load or not"
    CheckIfPartialData $idate$trans_hr
    scriptLogger $LOGFILE $PROCESS $$ "[INFO]" " Checking in Hive"  
  fi
  
  if [[ $flagWriteToctl -eq 1 ]]
  then
    #Adding next run timestamp to $KPI_CTL_FILE
    WriteToCtlFile $trans_dt $trans_hr
  fi

  CallPigScript $trans_dt $trans_hr

  rm -f $PIDFILE >>$LOGFILE 2>&1

  return $?
}

################################################################################
################################################################################
##### Function: Main
Main()
{
  PrepareEnv

  ValidateArgs $@

  scriptLogger $LOGFILE $PROCESS $$ "[INFO]"  "----- Process START -----"
  
  PIDFILE=$PERMITDIR/$PROCESS'_'$trans_dt'_'$trans_hr.pid
  
  InstanceCheck $trans_dt $trans_hr $PIDFILE

  #Update PID file
  WritePIDFile $PIDFILE

  CoreLogic $trans_dt $trans_hr
}

#################################################################################
#################################################################################
#################################################################################
#################################################################################

Main $@
